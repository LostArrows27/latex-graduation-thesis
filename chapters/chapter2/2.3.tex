\section{Công nghệ và phương pháp đo lường hiệu năng}

\subsection{Các công nghệ triển khai microservices}
Trong triển khai kiến trúc microservices, việc lựa chọn công nghệ phù hợp đóng vai trò quan trọng, ảnh hưởng trực tiếp đến hiệu suất, khả năng mở rộng và bảo trì của hệ thống \cite{newman2015}. Đánh giá này sử dụng NestJS làm framework chính cho việc phát triển các microservices. NestJS là một framework Node.js tiến bộ, được phát triển dựa trên TypeScript, cung cấp kiến trúc ứng dụng được lấy cảm hứng từ Angular với các nguyên tắc SOLID và mô hình MVC. Framework này mang lại nhiều lợi ích trong phát triển microservices như hỗ trợ dependency injection, kiến trúc mô-đun hóa cao và tích hợp sẵn với nhiều công nghệ khác nhau.

NestJS sử dụng kiến trúc module mạnh mẽ cho phép tổ chức mã nguồn thành các thành phần có thể tái sử dụng và dễ bảo trì. Mỗi microservice trong bài đánh giá được triển khai như một ứng dụng NestJS độc lập, với cấu trúc bao gồm controllers (xử lý các yêu cầu HTTP), services (chứa logic nghiệp vụ), modules (đóng gói các thành phần liên quan) và entities (đại diện cho các đối tượng dữ liệu). NestJS cũng cung cấp một module microservices chuyên dụng hỗ trợ các giao thức như TCP, Redis, MQTT, gRPC, và Kafka, giúp đơn giản hóa việc triển khai các mẫu giao tiếp khác nhau.

TypeScript được chọn làm ngôn ngữ lập trình chính vì nó mang lại lợi thế của hệ thống kiểu dữ liệu tĩnh, giúp phát hiện lỗi sớm trong quá trình phát triển, tăng cường khả năng đọc hiểu và bảo trì mã nguồn. TypeScript cho phép xác định các interface và type rõ ràng cho các đối tượng dữ liệu và yêu cầu API, giảm thiểu các lỗi liên quan đến kiểu dữ liệu và cải thiện khả năng đọc hiểu mã nguồn. Đặc biệt, trong môi trường microservices nơi các dịch vụ giao tiếp qua mạng, TypeScript giúp đảm bảo tính nhất quán của dữ liệu được truyền giữa các dịch vụ thông qua việc xác định các contract rõ ràng.

Để lưu trữ dữ liệu trong kiến trúc microservices, nguyên tắc "mỗi dịch vụ có cơ sở dữ liệu riêng" được tuân thủ nhằm đảm bảo tính độc lập của các dịch vụ. TypeORM, một Object-Relational Mapping framework hiện đại cho TypeScript và JavaScript, được sử dụng để tương tác với cơ sở dữ liệu. TypeORM hỗ trợ nhiều hệ quản trị cơ sở dữ liệu và cung cấp các tính năng như quan hệ, kế thừa, migrations và nhiều kiểu lưu trữ dữ liệu khác nhau.

TypeORM sử dụng cách tiếp cận Active Record và Data Mapper, cho phép linh hoạt trong việc tương tác với cơ sở dữ liệu. Các entity trong TypeORM được định nghĩa bằng cách sử dụng decorators, giúp đơn giản hóa việc ánh xạ từ đối tượng trong code đến bảng trong cơ sở dữ liệu. Ngoài ra, TypeORM còn hỗ trợ các tính năng nâng cao như lazy loading, eager loading, transactions và query builder, giúp tối ưu hóa hiệu suất truy vấn cơ sở dữ liệu.

PostgreSQL được chọn làm hệ quản trị cơ sở dữ liệu chính do tính ổn định, hiệu suất cao và khả năng xử lý dữ liệu quan hệ phức tạp. PostgreSQL cung cấp hỗ trợ mạnh mẽ cho các kiểu dữ liệu phức tạp như JSON, JSONB và arrays, rất phù hợp cho các ứng dụng microservices hiện đại. Khả năng xử lý đồng thời và hỗ trợ transaction của PostgreSQL đảm bảo tính nhất quán dữ liệu trong môi trường phân tán.

Đối với giao tiếp giữa các microservices, bài đánh giá sử dụng nhiều công nghệ khác nhau để triển khai các mẫu giao tiếp. HTTP/REST API là nền tảng cho giao tiếp đồng bộ, với Axios được sử dụng làm HTTP client trong NestJS. Axios cung cấp API dựa trên Promise, hỗ trợ các tính năng như interceptors, timeout, và xử lý lỗi tiên tiến. NestJS cung cấp một lớp HttpService được xây dựng trên Axios, giúp đơn giản hóa việc gọi API từ một microservice đến microservice khác.

Trong mô hình RESTful, các microservices giao tiếp thông qua HTTP với các endpoint được định nghĩa rõ ràng. Controllers trong NestJS được trang bị các decorator như @Get(), @Post(), @Put(), và @Delete() để xử lý các phương thức HTTP tương ứng. NestJS cũng hỗ trợ validation thông qua các pipe và interceptor, đảm bảo dữ liệu được gửi và nhận đúng định dạng.

RabbitMQ, một message broker mạnh mẽ và đáng tin cậy, được triển khai cho các mẫu giao tiếp Point-to-Point và Asynchronous Request-Response. RabbitMQ cung cấp cơ chế bảo đảm tin cậy cao với các tính năng như xác nhận tin nhắn, hàng đợi bền vững và routing linh hoạt. RabbitMQ triển khai giao thức AMQP (Advanced Message Queuing Protocol), cho phép giao tiếp tin cậy và bảo mật giữa các dịch vụ.

Trong mô hình Point-to-Point với RabbitMQ, mỗi tin nhắn được gửi từ một producer đến một consumer thông qua một hàng đợi. RabbitMQ đảm bảo rằng mỗi tin nhắn chỉ được xử lý bởi một consumer, ngay cả khi có nhiều consumer cùng theo dõi một hàng đợi. Điều này đặc biệt hữu ích cho các tác vụ cần được xử lý chính xác một lần, như cập nhật đơn hàng hoặc xử lý thanh toán.

Đối với mô hình Asynchronous Request-Response, RabbitMQ được cấu hình với các hàng đợi phản hồi tạm thời và correlation IDs để theo dõi mối quan hệ giữa yêu cầu và phản hồi. Khi một microservice gửi yêu cầu, nó tạo một correlation ID duy nhất và một hàng đợi phản hồi tạm thời. Microservice nhận xử lý yêu cầu và gửi phản hồi đến hàng đợi tạm thời với cùng correlation ID, cho phép microservice gốc xác định đúng phản hồi cho yêu cầu của nó.

Apache Kafka, một nền tảng xử lý luồng sự kiện phân tán, được sử dụng cho các mẫu giao tiếp Publish/Subscribe và Event-Driven. Kafka nổi bật với khả năng xử lý hàng triệu sự kiện mỗi giây, độ trễ thấp và khả năng lưu trữ sự kiện lâu dài. Mô hình bảo lưu log của Kafka cho phép consumers đọc lại các sự kiện từ bất kỳ thời điểm nào trong quá khứ, điều này đặc biệt hữu ích cho việc phân tích dữ liệu và khôi phục sau sự cố.

Trong mô hình Publish/Subscribe với Kafka, các microservices phát hành sự kiện đến các topic, và nhiều consumer có thể đăng ký để nhận các sự kiện này. Kafka hỗ trợ phân vùng topic, cho phép xử lý song song và cân bằng tải giữa nhiều consumer trong cùng một consumer group. Điều này cải thiện đáng kể khả năng mở rộng của hệ thống, đặc biệt là trong các trường hợp khối lượng sự kiện lớn.

Mô hình Event-Driven với Kafka tận dụng khả năng lưu trữ và phát lại sự kiện của nền tảng này. Các microservices phát hành sự kiện khi trạng thái của chúng thay đổi, và các dịch vụ khác phản ứng với những thay đổi này. Mô hình này tạo ra sự tách rời cao giữa các dịch vụ, vì service phát hành không cần biết về các dịch vụ nào đang lắng nghe sự kiện của nó.

NestJS cung cấp tích hợp cho cả RabbitMQ và Kafka thông qua module microservices, giúp đơn giản hóa việc triển khai các mẫu giao tiếp khác nhau. Module này cung cấp các decorators như @MessagePattern() và @EventPattern() để xử lý các tin nhắn và sự kiện từ các transport khác nhau. NestJS cũng hỗ trợ serialization và deserialization tự động, giúp đơn giản hóa việc chuyển đổi giữa các định dạng tin nhắn khác nhau.

\subsection{Các thông số đo lường chính}
Để đánh giá hiệu năng của các mẫu giao tiếp trong microservices, cần xem xét một tập hợp các thông số đo lường toàn diện. Latency (Độ trễ) là một trong những thông số quan trọng nhất, đại diện cho thời gian cần thiết để hoàn thành một yêu cầu, từ khi gửi đến khi nhận phản hồi \cite{jun2018}. Độ trễ thường được đo bằng mili giây (ms) và phản ánh trực tiếp trải nghiệm người dùng. Trong kiến trúc microservices, độ trễ có thể bị ảnh hưởng bởi nhiều yếu tố như khoảng cách vật lý giữa các dịch vụ, phương pháp tuần tự hóa dữ liệu, cơ chế giao tiếp được chọn và tải mạng.

Độ trễ trong microservices thường được phân tích theo nhiều khía cạnh khác nhau. Độ trễ đầu cuối (end-to-end latency) đo lường tổng thời gian từ khi client gửi yêu cầu đến khi nhận được phản hồi đầy đủ. Độ trễ dịch vụ (service latency) đo lường thời gian xử lý trong một microservice cụ thể, không bao gồm thời gian giao tiếp mạng. Độ trễ mạng (network latency) đo lường thời gian cần thiết để dữ liệu di chuyển giữa các dịch vụ qua mạng. Phân tách các loại độ trễ này giúp xác định chính xác các điểm nghẽn trong hệ thống và tối ưu hóa hiệu suất một cách có mục tiêu.

Trong các mẫu giao tiếp đồng bộ như Request-Response, độ trễ thường đơn giản để đo lường vì nó bằng với thời gian từ khi gửi yêu cầu đến khi nhận được phản hồi. Tuy nhiên, trong các mẫu giao tiếp bất đồng bộ, việc đo lường độ trễ phức tạp hơn. Đối với Asynchronous Request-Response, cần theo dõi thời gian từ khi gửi yêu cầu đến khi nhận được phản hồi bất đồng bộ, thường thông qua correlation IDs hoặc cơ chế tương tự. Đối với Event-Driven và Publish/Subscribe, độ trễ có thể được đo lường là thời gian từ khi một sự kiện được phát hành đến khi nó được xử lý bởi tất cả các consumer liên quan.

Throughput (Thông lượng) đo lường số lượng yêu cầu mà hệ thống có thể xử lý trong một đơn vị thời gian, thường được biểu thị bằng yêu cầu trên giây (RPS) hoặc giao dịch trên giây (TPS) \cite{jun2018}. Thông lượng cao là một chỉ số của hệ thống có khả năng xử lý đồng thời nhiều yêu cầu, điều này đặc biệt quan trọng cho các ứng dụng có tải cao \cite{aksakalli2021}.

Thông lượng trong microservices có thể được đo lường ở nhiều cấp độ khác nhau. Thông lượng hệ thống (system throughput) đo lường tổng số yêu cầu mà toàn bộ hệ thống có thể xử lý trong một giây. Thông lượng dịch vụ (service throughput) đo lường số lượng yêu cầu mà một microservice cụ thể có thể xử lý. Thông lượng endpoint (endpoint throughput) đo lường số lượng yêu cầu mà một endpoint cụ thể trong một dịch vụ có thể xử lý. Việc phân tích thông lượng ở các cấp độ khác nhau giúp xác định các điểm nghẽn và cơ hội mở rộng trong hệ thống.

Các mẫu giao tiếp khác nhau có thể ảnh hưởng đáng kể đến thông lượng của hệ thống. Các mẫu đồng bộ như Request-Response thường có thông lượng thấp hơn do tính chất tuần tự của chúng, trong khi các mẫu bất đồng bộ như Publish/Subscribe và Event-Driven có thể đạt thông lượng cao hơn do khả năng xử lý song song. Tuy nhiên, điều này phụ thuộc nhiều vào trường hợp sử dụng cụ thể và cách triển khai.

Error Rate (Tỷ lệ lỗi) là tỷ lệ phần trăm của các yêu cầu thất bại so với tổng số yêu cầu được gửi đến hệ thống \cite{newman2015}. Tỷ lệ lỗi có thể bị ảnh hưởng bởi nhiều yếu tố như lỗi mạng, lỗi dịch vụ, timeout hoặc lỗi logic nghiệp vụ \cite{richardson2019}. Một tỷ lệ lỗi cao không chỉ ảnh hưởng đến trải nghiệm người dùng mà còn làm giảm độ tin cậy tổng thể của hệ thống. Trong các mẫu giao tiếp bất đồng bộ, việc theo dõi và xử lý lỗi phức tạp hơn so với các mẫu đồng bộ, do đó tỷ lệ lỗi là một thông số đặc biệt quan trọng cần xem xét.

Trong kiến trúc microservices, các loại lỗi khác nhau có thể xảy ra, bao gồm lỗi mạng (network errors), lỗi thời gian chờ (timeout errors), lỗi dịch vụ (service errors) và lỗi logic nghiệp vụ (business logic errors). Mỗi loại lỗi cần được phân loại và xử lý riêng biệt. Ví dụ, lỗi mạng tạm thời có thể được giải quyết bằng cách thử lại, trong khi lỗi dịch vụ có thể yêu cầu failover sang một instance khác hoặc kích hoạt circuit breaker để ngăn chặn lỗi lan truyền.

Các mẫu giao tiếp khác nhau có cách tiếp cận khác nhau đối với xử lý lỗi. Trong Request-Response, lỗi thường được báo cáo ngay lập tức thông qua mã trạng thái HTTP hoặc thông báo lỗi. Trong Asynchronous Request-Response, lỗi có thể được báo cáo thông qua callback hoặc hàng đợi lỗi riêng biệt. Trong Event-Driven và Publish/Subscribe, việc xử lý lỗi phức tạp hơn và có thể yêu cầu cơ chế như dead-letter queues hoặc retry topics.

Resource Utilization (Sử dụng tài nguyên) đề cập đến lượng tài nguyên hệ thống như CPU, bộ nhớ và băng thông mạng được sử dụng bởi các microservices. Sử dụng tài nguyên cao có thể dẫn đến hiệu suất giảm và chỉ ra nhu cầu mở rộng theo chiều ngang hoặc tối ưu hóa hiệu suất. Trong bài đánh giá này, sử dụng tài nguyên được giám sát cho từng microservice riêng biệt cũng như cho toàn bộ hệ thống, cho phép phân tích chi tiết về hiệu quả sử dụng tài nguyên của mỗi mẫu giao tiếp.

Sử dụng CPU là một trong những thông số quan trọng nhất trong sử dụng tài nguyên. Nó đo lường tỷ lệ phần trăm thời gian CPU được sử dụng bởi các tiến trình microservice. Sử dụng CPU cao có thể chỉ ra nhu cầu tối ưu hóa mã nguồn hoặc mở rộng theo chiều ngang. Sử dụng bộ nhớ đo lường lượng RAM được sử dụng bởi các microservices. Sử dụng bộ nhớ cao có thể dẫn đến swapping và hiệu suất giảm. Băng thông mạng đo lường lượng dữ liệu được truyền qua mạng giữa các microservices. Băng thông mạng cao có thể chỉ ra nhu cầu tối ưu hóa định dạng dữ liệu hoặc giảm lượng dữ liệu được truyền.

Các mẫu giao tiếp khác nhau có yêu cầu tài nguyên khác nhau. Các mẫu đồng bộ như Request-Response thường có yêu cầu CPU và bộ nhớ thấp hơn nhưng có thể sử dụng nhiều kết nối mạng đồng thời. Các mẫu bất đồng bộ như Publish/Subscribe và Event-Driven có thể có yêu cầu CPU và bộ nhớ cao hơn do cần xử lý và lưu trữ tin nhắn, nhưng chúng thường sử dụng kết nối mạng hiệu quả hơn do khả năng batch processing.

Scalability (Khả năng mở rộng) đo lường khả năng của hệ thống trong việc xử lý tải tăng bằng cách thêm tài nguyên. Khả năng mở rộng tốt có nghĩa là hiệu suất tăng tỷ lệ thuận với tài nguyên được thêm vào. Các mẫu giao tiếp khác nhau có thể ảnh hưởng đáng kể đến khả năng mở rộng của hệ thống microservices. Ví dụ, các mẫu bất đồng bộ thường có khả năng mở rộng tốt hơn so với các mẫu đồng bộ do chúng tạo ra ít sự phụ thuộc trực tiếp hơn giữa các dịch vụ.

Khả năng mở rộng theo chiều ngang (horizontal scalability) đề cập đến khả năng tăng hiệu suất bằng cách thêm nhiều instance của các microservices. Khả năng mở rộng theo chiều dọc (vertical scalability) đề cập đến khả năng tăng hiệu suất bằng cách thêm tài nguyên cho các instance hiện có. Trong kiến trúc microservices, khả năng mở rộng theo chiều ngang thường được ưu tiên do tính linh hoạt và khả năng chịu lỗi cao hơn.

Các mẫu giao tiếp khác nhau hỗ trợ khả năng mở rộng theo những cách khác nhau. Các mẫu đồng bộ như Request-Response có thể gặp khó khăn khi mở rộng do yêu cầu kết nối trực tiếp giữa các dịch vụ. Điều này có thể được giải quyết bằng cách sử dụng load balancer hoặc API gateway. Các mẫu bất đồng bộ như Publish/Subscribe và Event-Driven thường có khả năng mở rộng tốt hơn do chúng tách rời các producer và consumer, cho phép chúng mở rộng độc lập.

Consistency (Tính nhất quán) trong context của microservices là khả năng duy trì trạng thái dữ liệu đồng bộ giữa các dịch vụ khác nhau. Đối với các mẫu giao tiếp đồng bộ, tính nhất quán thường dễ đạt được hơn do tính chất tuần tự của các hoạt động. Tuy nhiên, đối với các mẫu bất đồng bộ, đặc biệt là trong các kịch bản phân tán dữ liệu, tính nhất quán trở thành một thách thức và cần được đo lường cẩn thận. bài đánh giá này đánh giá mức độ nhất quán dữ liệu đạt được bởi các mẫu giao tiếp khác nhau trong các kịch bản như kiểm tra tồn kho và cập nhật đơn hàng.

Tính nhất quán mạnh (strong consistency) đảm bảo rằng tất cả các dịch vụ luôn nhìn thấy dữ liệu mới nhất. Điều này thường đạt được thông qua các giao thức phức tạp hoặc truy cập trực tiếp đến cùng một cơ sở dữ liệu. Tính nhất quán cuối cùng (eventual consistency) chấp nhận rằng các dịch vụ có thể tạm thời nhìn thấy dữ liệu không đồng bộ, nhưng cuối cùng tất cả sẽ đồng bộ. Mô hình này thường được sử dụng trong các hệ thống phân tán quy mô lớn do tính thực tế và hiệu suất cao hơn.

Các mẫu giao tiếp khác nhau hỗ trợ các mô hình nhất quán khác nhau. Các mẫu đồng bộ như Request-Response thường hỗ trợ tính nhất quán mạnh do tính chất tuần tự của chúng. Các mẫu bất đồng bộ như Publish/Subscribe và Event-Driven thường hỗ trợ tính nhất quán cuối cùng, đòi hỏi thiết kế cẩn thận để đảm bảo dữ liệu cuối cùng sẽ đồng bộ.

\subsection{Phương pháp đo lường}
Để thu thập dữ liệu hiệu năng toàn diện về các mẫu giao tiếp microservices, bài đánh giá này áp dụng nhiều phương pháp đo lường bổ sung cho nhau \cite{newman2015}. Load Testing (Kiểm thử tải) là một phương pháp cơ bản được sử dụng để mô phỏng các điều kiện tải thực tế và đánh giá hiệu năng của hệ thống dưới áp lực \cite{jun2018}. Thông qua kiểm thử tải, các điểm nghẽn, giới hạn và điểm lỗi trong hệ thống có thể được xác định. Trong bài đánh giá này, các kịch bản kiểm thử tải được thiết kế để mô phỏng các trường hợp sử dụng thực tế như kiểm tra tồn kho, xử lý thanh toán và thông báo đơn hàng với các mức tải khác nhau.

Kiểm thử tải có thể được thực hiện theo nhiều cách khác nhau, bao gồm kiểm thử tăng dần (ramp-up testing), kiểm thử chịu tải (stress testing), kiểm thử phá vỡ (spike testing) và kiểm thử độ bền (endurance testing). Kiểm thử tăng dần tăng tải từ từ, cho phép đánh giá hiệu suất của hệ thống khi tải tăng lên. Kiểm thử chịu tải đẩy hệ thống đến giới hạn để xác định điểm vỡ. Kiểm thử phá vỡ đánh giá phản ứng của hệ thống đối với sự gia tăng tải đột ngột. Kiểm thử độ bền đánh giá hiệu suất của hệ thống trong thời gian dài.

Trong bài đánh giá này, các kịch bản kiểm thử tải được thiết kế để mô phỏng các trường hợp sử dụng thực tế của hệ thống microservices. Các kịch bản này bao gồm các hoạt động như tạo đơn hàng, kiểm tra tồn kho, xử lý thanh toán và gửi thông báo. Mỗi kịch bản được thiết kế để tập trung vào một mẫu giao tiếp cụ thể, cho phép so sánh trực tiếp hiệu suất của các mẫu khác nhau trong cùng một ngữ cảnh.

Benchmarking (Đánh giá) là phương pháp so sánh hiệu năng của các cấu hình hệ thống khác nhau trong điều kiện tiêu chuẩn \cite{richardson2019}. Benchmarking cho phép xác định cấu hình hiệu quả nhất cho một trường hợp sử dụng cụ thể và theo dõi hiệu năng theo thời gian khi hệ thống phát triển. Trong bài đánh giá này, benchmarking được sử dụng để so sánh hiệu suất của các mẫu giao tiếp khác nhau dưới các điều kiện tải giống nhau, cung cấp cái nhìn trực quan về hiệu quả tương đối của mỗi mẫu.

Việc thiết lập benchmark chuẩn đòi hỏi sự cẩn thận trong thiết kế thử nghiệm để đảm bảo kết quả có ý nghĩa và có thể tái hiện. Điều này bao gồm việc kiểm soát môi trường thử nghiệm, chẳng hạn như cấu hình phần cứng và phần mềm, tải nền và độ trễ mạng. Cũng cần xác định các metric phù hợp để đo lường, chẳng hạn như thời gian phản hồi, thông lượng và sử dụng tài nguyên.

Trong bài đánh giá này, benchmark được tiến hành cho mỗi mẫu giao tiếp với các trường hợp thử nghiệm giống nhau, bao gồm Order-Inventory, Order-Payment và Order-Notification. Mỗi trường hợp thử nghiệm được chạy với các mức tải tăng dần, từ 10 đến 100 người dùng đồng thời, để đánh giá khả năng mở rộng của mỗi mẫu. Các metric được thu thập bao gồm thời gian phản hồi trung bình, thời gian phản hồi phân vị thứ 95, thông lượng, tỷ lệ lỗi và sử dụng tài nguyên.

Một khía cạnh quan trọng của benchmarking là khả năng so sánh hiệu suất tương đối của các mẫu giao tiếp khác nhau. Trong bài đánh giá này, các bảng và biểu đồ so sánh được tạo để trực quan hóa sự khác biệt về hiệu suất giữa các mẫu. Điều này giúp xác định mẫu nào phù hợp nhất cho các trường hợp sử dụng cụ thể, dựa trên các yêu cầu về hiệu suất và khả năng mở rộng.

Profiling (Lập hồ sơ) là một phương pháp phân tích chi tiết tài nguyên được sử dụng và thời gian thực thi của các thành phần hệ thống. Profiling cung cấp thông tin chi tiết về hiệu suất của các phần cụ thể trong mã nguồn và giúp xác định các đoạn mã không hiệu quả hoặc sử dụng tài nguyên nhiều. Bằng cách phân tích dữ liệu profiling, các cơ hội tối ưu hóa hiệu suất có thể được xác định và triển khai.

Trong môi trường Node.js, profiling có thể được thực hiện bằng cách sử dụng các công cụ như Node.js Profiler, Chrome DevTools Profiler hoặc các thư viện bên thứ ba như clinic.js. Các công cụ này cho phép thu thập dữ liệu về thời gian CPU, sử dụng bộ nhớ, hoạt động của garbage collector và các chỉ số hiệu suất khác. Dữ liệu này có thể được phân tích để xác định các điểm nghẽn hiệu suất và tối ưu hóa mã nguồn.

Trong bài đánh giá này, profiling được sử dụng để phân tích hiệu suất của các thành phần khác nhau trong mỗi mẫu giao tiếp. Cụ thể, profiling giúp xác định thời gian dành cho việc serialization/deserialization dữ liệu, xử lý mạng, xử lý logic nghiệp vụ và tương tác với cơ sở dữ liệu. Thông tin này rất có giá trị trong việc hiểu rõ hơn về hiệu quả của mỗi mẫu giao tiếp và xác định các cơ hội tối ưu hóa.

Một khía cạnh quan trọng của profiling trong kiến trúc microservices là khả năng phân tích hiệu suất xuyên suốt các dịch vụ. Điều này đòi hỏi sự phối hợp trong việc thu thập và phân tích dữ liệu profiling từ nhiều dịch vụ, thường thông qua các công cụ như distributed tracing. Bằng cách kết hợp dữ liệu profiling từ nhiều dịch vụ, có thể xác định các tương tác không hiệu quả giữa các dịch vụ và tối ưu hóa hiệu suất tổng thể của hệ thống.

Distributed Tracing (Theo dõi phân tán) là phương pháp theo dõi yêu cầu khi chúng đi qua nhiều dịch vụ trong một hệ thống phân tán. Phương pháp này đặc biệt quan trọng trong kiến trúc microservices, nơi một yêu cầu người dùng có thể đi qua nhiều dịch vụ khác nhau trước khi hoàn thành. Distributed tracing giúp xác định các điểm nghẽn, hiểu luồng yêu cầu và mối quan hệ phụ thuộc giữa các dịch vụ. Trong bài đánh giá này, distributed tracing được sử dụng để phân tích chi tiết luồng giao tiếp giữa các microservices và xác định các điểm tối ưu tiềm năng.

Trong môi trường Node.js, distributed tracing có thể được triển khai bằng cách sử dụng các thư viện như OpenTelemetry, một framework mã nguồn mở cung cấp API, thư viện và tác nhân để thu thập dữ liệu theo dõi phân tán. OpenTelemetry có thể được tích hợp với NestJS thông qua các interceptor và middleware, cho phép tự động thu thập dữ liệu tracing từ các yêu cầu HTTP và các tương tác microservices.

Mỗi trace trong distributed tracing đại diện cho một yêu cầu đi qua hệ thống và bao gồm một hoặc nhiều span. Mỗi span đại diện cho một hoạt động đơn lẻ trong trace, chẳng hạn như yêu cầu HTTP, truy vấn cơ sở dữ liệu hoặc xử lý logic nghiệp vụ. Spans được tổ chức thành một cấu trúc phân cấp, với các span con lồng bên trong các span cha, tạo thành một cây trace. Thông tin này cho phép hiểu rõ về luồng yêu cầu và các mối quan hệ phụ thuộc giữa các hoạt động.

Trong bài đánh giá này, distributed tracing được sử dụng để phân tích chi tiết luồng yêu cầu trong mỗi mẫu giao tiếp. Cụ thể, nó giúp xác định thời gian dành cho các hoạt động khác nhau trong quá trình xử lý yêu cầu, chẳng hạn như giao tiếp giữa các dịch vụ, xử lý logic nghiệp vụ và tương tác với cơ sở dữ liệu. Thông tin này rất có giá trị trong việc hiểu rõ hơn về hiệu quả của mỗi mẫu giao tiếp và xác định các cơ hội tối ưu hóa.

Metrics Collection (Thu thập số liệu) là quá trình thu thập và phân tích các chỉ số hiệu năng của hệ thống theo thời gian. Metrics collection cho phép theo dõi xu hướng hiệu năng, phát hiện bất thường và thiết lập cảnh báo cho các vấn đề tiềm ẩn. Trong bài đánh giá này, các số liệu như thời gian phản hồi, tỷ lệ lỗi, thông lượng và sử dụng tài nguyên được thu thập liên tục từ tất cả các microservices và các thành phần hỗ trợ như message broker và cơ sở dữ liệu.

Trong môi trường Node.js, metrics collection có thể được triển khai bằng cách sử dụng các thư viện như Prom-Client, một thư viện mã nguồn mở cung cấp các primitive để thu thập và hiển thị metrics trong định dạng mà Prometheus có thể hiểu được. Prom-Client có thể được tích hợp với NestJS thông qua một module tùy chỉnh, cho phép tự động thu thập các metrics tiêu chuẩn như thời gian phản hồi HTTP, số lượng yêu cầu đang xử lý và sử dụng bộ nhớ.

Các loại metrics khác nhau có thể được thu thập, bao gồm counters, gauges, histograms và summaries. Counters là các giá trị chỉ tăng lên, được sử dụng để đếm các sự kiện như số lượng yêu cầu hoặc lỗi. Gauges là các giá trị có thể tăng hoặc giảm, được sử dụng để đo lường các giá trị như số lượng kết nối đồng thời hoặc kích thước hàng đợi. Histograms và summaries đo lường phân phối các giá trị như thời gian phản hồi hoặc kích thước yêu cầu, cho phép tính toán các percentile như p50, p95 và p99.

Trong bài đánh giá này, metrics collection được sử dụng để thu thập dữ liệu hiệu năng từ tất cả các microservices và các thành phần hỗ trợ. Cụ thể, các metrics sau đây được thu thập:

\begin{itemize}
    \item HTTP metrics: Thời gian phản hồi, tỷ lệ lỗi và số lượng yêu cầu cho mỗi endpoint HTTP.
    \item Microservice metrics: Thời gian xử lý, tỷ lệ lỗi và số lượng tin nhắn cho mỗi pattern microservice.
    \item Database metrics: Thời gian truy vấn, số lượng truy vấn và số lượng kết nối cho mỗi cơ sở dữ liệu.
    \item Message broker metrics: Kích thước hàng đợi, tốc độ tin nhắn và độ trễ tin nhắn cho mỗi hàng đợi hoặc topic.
    \item System metrics: Sử dụng CPU, sử dụng bộ nhớ và băng thông mạng cho mỗi service.
\end{itemize}

Dữ liệu metrics được thu thập và lưu trữ trong một hệ thống time-series database, cho phép truy vấn và phân tích dữ liệu theo thời gian. Điều này cho phép theo dõi xu hướng hiệu năng, phát hiện bất thường và thiết lập cảnh báo cho các vấn đề tiềm ẩn. Dữ liệu metrics cũng được sử dụng để tạo bảng điều khiển hiển thị hiệu suất của hệ thống theo thời gian thực, giúp giám sát và khắc phục sự cố.

\subsection{Công cụ đo lường hiệu năng}
Để thực hiện các phương pháp đo lường đã nêu, bài đánh giá triển khai một bộ công cụ toàn diện cho việc thu thập và phân tích dữ liệu hiệu năng \cite{aksakalli2021}. K6, một công cụ kiểm thử tải mã nguồn mở dựa trên JavaScript, được sử dụng để tạo tải và đo lường hiệu năng của các mẫu giao tiếp microservices khác nhau \cite{jun2018}. K6 cho phép viết các tập lệnh kiểm thử phức tạp mô phỏng hành vi người dùng thực tế, hỗ trợ thực hiện các yêu cầu HTTP, WebSocket và gRPC. Ngoài ra, K6 cung cấp tính năng phân tích dữ liệu tích hợp, cho phép tính toán các số liệu thống kê về độ trễ, thông lượng và tỷ lệ lỗi.

K6 nổi bật với khả năng mở rộng và tùy chỉnh cao. Nó cho phép viết các tập lệnh kiểm thử bằng JavaScript hiện đại, với hỗ trợ cho các tính năng như async/await, modules và promises. K6 cũng cung cấp một API phong phú để tạo và kiểm soát tải, bao gồm các chức năng như ramp-up, constant load, và step-load. Điều này cho phép mô phỏng các tình huống tải thực tế và đánh giá hiệu năng của hệ thống dưới các điều kiện khác nhau.

Trong đánh giá này, K6 được sử dụng để tạo tải và đo lường hiệu năng của các mẫu giao tiếp microservices khác nhau. Các tập lệnh K6 được viết để mô phỏng các kịch bản thực tế như kiểm tra tồn kho, xử lý thanh toán và thông báo đơn hàng. Mỗi tập lệnh được thiết kế để tập trung vào một mẫu giao tiếp cụ thể, cho phép so sánh trực tiếp hiệu suất của các mẫu khác nhau trong cùng một ngữ cảnh.

Ví dụ, để kiểm thử hiệu năng của mẫu giao tiếp Request-Response trong kịch bản kiểm tra tồn kho, K6 được cấu hình để gửi yêu cầu HTTP GET đến endpoint /inventory/check/{productId} của Order Service. Thời gian phản hồi, tỷ lệ lỗi và thông lượng được đo lường và so sánh với các mẫu giao tiếp khác như Asynchronous Request-Response và Publish/Subscribe.

Prometheus, một hệ thống giám sát mã nguồn mở, được triển khai để thu thập và lưu trữ các số liệu hiệu năng từ các microservices \cite{richardson2019}. Prometheus sử dụng mô hình pull để thu thập số liệu, trong đó nó truy vấn định kỳ các mục tiêu được cấu hình \cite{newman2015}. Mô hình này đơn giản hóa việc triển khai và mở rộng, đồng thời cung cấp khả năng phát hiện tự động các instance mới. Prometheus cũng cung cấp ngôn ngữ truy vấn mạnh mẽ PromQL, cho phép truy vấn và phân tích phức tạp các số liệu thu thập được.

Prometheus nổi bật với khả năng mở rộng và tính tin cậy cao. Nó sử dụng một mô hình dữ liệu time-series hiệu quả, cho phép lưu trữ và truy vấn hàng triệu time-series với hiệu suất cao. Prometheus cũng cung cấp một hệ thống cảnh báo mạnh mẽ, cho phép định nghĩa các quy tắc cảnh báo dựa trên các biểu thức PromQL. Khi một quy tắc cảnh báo được kích hoạt, Prometheus có thể gửi thông báo đến các hệ thống như Alertmanager, Slack hoặc Email.

Trong đánh giá này, Prometheus được triển khai để thu thập các metric từ các microservices, bao gồm thời gian phản hồi, tỷ lệ lỗi và sử dụng tài nguyên. Các microservices được cấu hình để hiển thị các endpoint metrics mà Prometheus có thể truy vấn, thường là /metrics. Prometheus được cấu hình để truy vấn các endpoint này định kỳ, thường là mỗi 15 giây, và lưu trữ các giá trị thu thập được trong cơ sở dữ liệu time-series của nó.

Các metric được thu thập bởi Prometheus bao gồm các metric hệ thống như sử dụng CPU, sử dụng bộ nhớ và băng thông mạng, cũng như các metric ứng dụng như thời gian phản hồi HTTP, tỷ lệ lỗi và số lượng yêu cầu. Các metric này được sử dụng để phân tích hiệu suất của các mẫu giao tiếp khác nhau và xác định các điểm nghẽn và cơ hội tối ưu hóa.

Việc kết hợp các công nghệ triển khai và công cụ đo lường hiệu năng này tạo thành một môi trường toàn diện cho việc đánh giá và so sánh các mẫu giao tiếp khác nhau trong kiến trúc microservices. Thông qua việc thu thập và phân tích dữ liệu hiệu năng từ nhiều góc độ, nghiên cứu có thể cung cấp cái nhìn sâu sắc về ưu và nhược điểm của mỗi mẫu giao tiếp và đưa ra khuyến nghị dựa trên bằng chứng cho việc lựa chọn mẫu giao tiếp phù hợp trong các tình huống khác nhau.